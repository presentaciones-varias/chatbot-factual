---
pagetitle: "Presentacion"
format:
  revealjs:
    css: ine_quarto_style_v2025_v2.css
    width: 2560      # ancho l贸gico de la slide
    height: 1440     # alto l贸gico de la slide
    margin: 0
---

## { .portada  #portada}

<div class="logo-box">
  <img src="imagenes/logo_portada3.png">
</div>

<div class="title-area">
  <h1>Presentaciones internas: Chatbot factual</h1>
  
  <h2>Unidad de Gobierno de Datos</h2>
  
  <p><strong>30 de octubre 2025</strong></p>
</div>


## Contenidos 

- Motivaci贸n
- Arquitectura
  - Open-WebUI
  - Ollama
  - PostgreSQL
- Desaf铆os
- Demostraci贸n en vivo
- Pr贸ximos pasos

## Motivaci贸n

::: {style="display: flex; align-items: center; justify-content: space-between; gap: 20px;"}

::: {style="display: flex; align-items: center; gap: 20px;"}

::: r-stack

![](imagenes/juan.png){height="400px" width="350px"}

::: {.fragment fragment-index=3}
![](imagenes/chad.jpg){height="400px" width="350px"}

:::

:::

::: r-stack
::: {.fragment .fade-in-then-out fragment-index=1 }
![](imagenes/dialog1.png)
:::
:::  {.fragment fragment-index=3}
![](imagenes/dialog3.png)
:::
:::
:::

::: {style="display: flex; align-items: center; gap: 20px;"}
::: r-stack
:::  {.fragment fragment-index=2}
![](imagenes/dialog2.png)
:::
:::

![](imagenes/mirror.gif)
:::

:::


::: {.fragment fragment-index=4}
**El problema de las alucinaciones en LLMs**

::: incremental
- Sabemos que los chatbots basados en LLMs tienden a generar informaci贸n inexacta o "alucinar"
  - Adem谩s tienden a halagar de m谩s a los usuarios (sicofancia LLM)
- Para usuarios que buscan **estad铆sticas oficiales**, esto representa un riesgo significativo
- La confiabilidad de los datos es fundamental en nuestro contexto
:::

:::

## Soluci贸n


::: columns
::: column
![](imagenes/meme.png)
:::

::: column
- Desarrollamos un chatbot que se conecta **directamente a datos oficiales**
- Se le "ense帽a" a no dar informaci贸n que no conozca
- Esto garantizar铆a respuestas basadas en informaci贸n verificada y autorizada
- Combina la interacci贸n natural de un chatbot con la precisi贸n de datos oficiales
:::
:::

## Arquitectura

:::: {.columns}

::: {.column width="30%"}
**Soluci贸n basada en contenedores Docker**

Tres componentes principales que interact煤an entre s铆:

- **Open-WebUI**: Interfaz de usuario para la interacci贸n con el chatbot
- **Ollama**: Motor de inferencia para los modelos de lenguaje
- **PostgreSQL**: Base de datos para almacenamiento persistente
:::

::: {.column width="70%"}
![](imagenes/diagrama_chatbot_factual.png){width=100% height=auto}
:::

::::

## Open-WebUI

:::: columns

::: {.column width="55%}
**驴Qu茅 es Open-WebUI?**

::: incremental
- Interfaz web de c贸digo abierto dise帽ada para interactuar con modelos de lenguaje
- Experiencia similar a ChatGPT pero auto-hospedada (_self-hosted_)
- Al ser open source, es altamente personalizable y extensible
:::

**Caracter铆sticas principales**

::: incremental
- Interfaz de chat intuitiva y moderna
- Soporte para m煤ltiples modelos simult谩neos
- Sistema de **herramientas (tools)** personalizables basadas en Python  para extender funcionalidades
- Gesti贸n de usuarios y permisos
- Historial de conversaciones persistente
:::

:::

::: {.column  width="45%"}

::: incremental
**En el proyecto**

- Act煤a como la capa de presentaci贸n del chatbot
- Permite a los usuarios hacer consultas en lenguaje natural
- Integra herramientas personalizadas para acceder a datos oficiales
- Facilita la autenticaci贸n y gesti贸n de sesiones
:::

**Ventajas**

::: incremental
- No depende de servicios externos
- Control total sobre datos y privacidad
- Much铆simo m谩s sencillo que desarrollar nuestro propio software de chat.
:::

::: {.align-right}
![](imagenes/owui.png){height=400px}
:::

:::

::::


## Open-WebUI

::: align-center
![](imagenes/pantallazo_owui.png){height=1000px }
:::


## Ollama

:::: columns

::: {.column width="55%"}
**驴Qu茅 es?**

::: incremental
- Plataforma de c贸digo abierto para ejecutar LLMs localmente
- Simplifica su descarga, gesti贸n y ejecuci贸n
:::

**Caracter铆sticas clave**

::: incremental
- Soporte para m煤ltiples modelos (Qwen, Llama, Gemma, etc.)
- Gesti贸n autom谩tica de memoria y recursos
- Optimizaciones de rendimiento para CPUs y GPUs
- API compatible con OpenAI haciendo f谩cil su integraci贸n
:::

:::

::: {.column width="45%"}

**En nuestro proyecto**

::: incremental
- Motor de inferencia que procesa las consultas del usuario
- Ejecuta el modelo de lenguaje que interpreta preguntas
- Genera respuestas contextuales basadas en la informaci贸n disponible
- Se comunica con Open-WebUI a trav茅s de su API
:::

**Ventajas**

::: incremental
- Ejecuci贸n local sin dependencia de APIs externas 
- Control sobre versiones de modelos
- Latencia reducida al eliminar llamadas a servicios remotos
- Sin l铆mites de uso o costos por token
:::

::: {.align-right}
![](imagenes/ollama.png){height=200px}
:::

:::

::::

## PostgreSQL

- Ya sabemos qu茅 es PostgreSQL, pero aprovecho de mostrar la estructura de las bases de datos.

![](imagenes/sql.PNG){height=750px}

- Podr铆amos quitar columnas para disminuir la complejidad del trabajo de la LLM: debi茅semos apuntar
a mantener la informaci贸n m铆nima posible para que cumpla su tarea con 茅xito.

## PostgreSQL

- Ya sabemos qu茅 es PostgreSQL, pero aprovecho de mostrar la estructura de las bases de datos.

![](imagenes/sql2.PNG){height=750px}

- Podr铆amos quitar columnas para disminuir la complejidad del trabajo de la LLM: debi茅semos apuntar
a mantener la informaci贸n m铆nima posible para que cumpla su tarea con 茅xito.


## Desaf铆os

**Documentaci贸n limitada**

- Open-WebUI presenta documentaci贸n deficiente
- Necesidad de explorar el c贸digo fuente directamente
- Ajustes espec铆ficos como carga de modelos y herramientas requieren investigaci贸n profunda
  - Vamos a tener que ver c贸mo darle memoria a las herramientas del modelo.
- Configuraci贸n para persistencia al detener contenedores

## Desaf铆os

:::: columns

::: {.column width="50%"}

::: {.fragment fragment-index=1}
**Ejemplo: mala documentaci贸n**. Quer铆a cargar mis herramientas (b谩sicamente funciones de Python con configuraci贸n extra) 
directamente al levantar la imagen. Caso contrario tengo que importarlas cada vez que levanto la imagen.
:::

::: {.fragment fragment-index=2}
La documentaci贸n solo menciona la opci贸n de importar o exportar herramientas. 
Queda como opci贸n revisar el c贸digo fuente hasta encontrar d贸nde se mencionan las herramientas
que desarroll茅.
:::

::: {.fragment fragment-index=3}
Encuentro que se mencionan en un archivo `webui.db`, es decir, en una base de datos de SQLite.
:::

::: {.fragment fragment-index=5}
**Soluci贸n**: exportar herramienta configurada como `.json`, luego crear un script que poble las
bases de datos desde los `.json` al levantar la imagen
:::

:::

::: {.column width="50%"}

::: {.r-stack}

::: {.fragment .fade-in-then-out fragment-index=1} 
![](imagenes/owui_tool.png){height=1000px}

:::



::: {.fragment .fade-in-then-out fragment-index=3} 

![](imagenes/webui_db.png){height="1000px"}
:::

::: {.fragment .fade-in-then-out fragment-index=4} 

![](imagenes/owui_tool_match.png){width="1000px"}
:::

::: {.fragment .fade-in-then-out fragment-index=5} 

![](imagenes/tool_json.png){width="1000px"}
:::

::: {.fragment .fade-in-then-out fragment-index=6} 

![](imagenes/import_tools.png){width="900px"}
:::

:::

:::

::::

## Desaf铆os

:::: columns

::: {.column width="50%"}
**Ejemplo: falta de memoria en herramienta**. 

::: {.fragment fragment-index=1}
Para un primer mensaje funciona bien
:::

::: {.fragment fragment-index=3}
Sin embargo, al tratar de continuar la interacci贸n utilizando lenguaje natural,
esta falla.
:::

::: {.fragment fragment-index=4}
Al investigar, se ve que es un problema de contexto.
:::

::: {.fragment fragment-index=5}
~~Actualmente investigando potenciales soluciones ~~

Al cambiar el flujo de las herramientas comenz贸 a funcionar.
:::


:::


::: {.column width="50%"}


:::: r-stack
::: {.fragment .fade-out fragment-index=2}
![Funciona bien originalmente](imagenes/ejemplo_2_1.png){width="1500px"}
:::

::: {.fragment .fade-in-then-out fragment-index=3}
![Siguiente interacci贸n falla (valor mujeres es falso)](imagenes/ejemplo_2_2.png){width="1500px"}
:::


::: {.fragment .fade-in fragment-index=4}
![Vemos que herramienta recibe mensaje libre de contexto](imagenes/ejemplo_2_3.png){width="1500px"}
:::


::::

:::
::::
## Desaf铆os

**Escalabilidad**

- Cargar un LLM es computacionalmente intensivo
- Dificultad para servir a m煤ltiples usuarios simult谩neos
- Requiere planificaci贸n cuidadosa de recursos

## Demostraci贸n en vivo

Y ahora veremos [c贸mo funciona en la pr谩ctica](http://10.0.40.64:3030/)

## Pr贸ximos pasos

**Expansi贸n y mejoras**

::: {.incremental}
- **Ampliar cobertura**: Expandir el n煤mero de indicadores disponibles
- **Desarrollo de API**: Estudiar la posibilidad de desarrollar una API dedicada para la conexi贸n de herramientas
- **Protocolo MCP**: Evaluar la implementaci贸n de Model Context Protocol (MCP) para las herramientas
- **M谩s pruebas de seguridad**: Tenemos que asegurarnos que en una gran mayor铆a de casos
  el chatbot no entregue informaci贸n inventada.
:::

## { .portada #cierre}

<div class="logo-box">
  <img src="imagenes/logo_portada3.png" class="portada-logo" alt="Logo">
</div>

<div class="title-area">
  <h1>Presentaciones internas: Chatbot factual</h1>
  
  <h2>Unidad de Gobierno de Datos</h2>
  
  <p><strong>30 de octubre 2025</strong></p>
</div>

